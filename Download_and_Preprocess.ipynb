{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "import oandapy\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_noise_all(x):\n",
    "    # Pandas ranking function does not have a random sort in case of ties.\n",
    "    # Add tiny bit of noise to variable to be ranked as a tie breaker\n",
    "    return x - np.random.normal(0, 0.0000001)\n",
    "\n",
    "\n",
    "# Calculate returns\n",
    "def calc_returns(df):\n",
    "    # df is the dataframe passed to the function, comprised of the exchange rates\n",
    "    # Calculate log returns\n",
    "    df = df.applymap(np.log)\n",
    "    df = df.diff().dropna()\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Filter intervals such that returns are only kept for consecutive timepoints.\n",
    "def interval_filter(df):\n",
    "    # To implement: variable time intervals for filtering\n",
    "    ix_name = df.index.name\n",
    "    df = df.reset_index()\n",
    "    df.loc[:, \"deltat\"] = pd.to_datetime(df.loc[:, ix_name]).diff()\n",
    "    df = df.drop('EUR_EUR', axis=1).replace(0.0, np.NaN).dropna()\n",
    "    df.insert(0, 'EUR_EUR', 0.)\n",
    "    df = df.query(\"deltat=='0 days 00:10:00' | deltat=='2 days 00:10:00' | deltat=='1 days 00:10:00'\")\n",
    "    df = df.set_index(\"time\").drop(\"deltat\", axis=1)\n",
    "    return df.reindex(sorted(df.columns), axis=1)\n",
    "\n",
    "\n",
    "    # Rank returns\n",
    "def calc_ranks(df):\n",
    "    no_curr = df.shape[1]\n",
    "    # df is the dataframe passed to the function, comprised of the returns\n",
    "    \n",
    "    # Rank per row\n",
    "    df = df.rank(axis=1, numeric_only=True, method='first')\n",
    "    # Apply the rescale per row.\n",
    "    df = 2*df - (no_curr+1)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set initial year for data y1, end year of data y2, granularity of data gran.\n",
    "y1 = '2005'\n",
    "y2 = '2018'\n",
    "gran = 'M10'\n",
    "\n",
    "# Open oanda client with access token in practice environmet\n",
    "with open(\"Oanda_Access_Token.txt\", \"r\") as f:\n",
    "    access_token = f.readline()\n",
    "    \n",
    "oanda  = oandapy.API(environment=\"practice\",\n",
    "                     access_token=access_token)\n",
    "\n",
    "\n",
    "# Set Default Values for M10\n",
    "# \n",
    "# Granularity of data in pandas freq, and as integer in minutes dl_interval,\n",
    "# Granularity for output format granop, interval size as tine step diff,\n",
    "# offset between two different download attempts offset (5000 is maximum via oanda)\n",
    "freq = '10T'\n",
    "dl_interval = 10\n",
    "granop = gran\n",
    "diff = '0 days, 00:10:00'\n",
    "offset = pd.DateOffset(minutes=4800*int(dl_interval))\n",
    "\n",
    "## Potential customization for other intervals to write as function\n",
    "# dl_interval = gran[1:]\n",
    "\n",
    "# if gran[0] == 'M':\n",
    "# \tfreq = dl_interval + 'T'\n",
    "# \tif len(gran) == 2:\n",
    "# \t\tgranop = 'M0' + dl_interval\n",
    "# \t\tdiff = '0 days, 00:0' + dl_interval + ':00'\n",
    "# \telse:\n",
    "# \t\tgranop = 'M' + dl_interval\n",
    "# \t\tdiff = '0 days, 00:' + dl_interval + ':00'\n",
    "# \toffset = pd.DateOffset(minutes=4800*int(dl_interval))\n",
    "\t\n",
    "# elif gran[0] == 'H':\n",
    "# \tfreq = str(dl_interval) + 'H'\n",
    "# \tif len(gran) == 2:\n",
    "# \t\tgranop = 'H0' + str(dl_interval)\n",
    "# \t\tdiff = '0 days, 0' + dl_interval + ':00:00'\n",
    "# \telse:\n",
    "# \t\tgranop = 'H' + str(dl_interval)\n",
    "# \t\tdiff = '0 days, ' + dl_interval + ':00:00'\n",
    "# \toffset = pd.DateOffset(hours=4800*int(dl_interval))\n",
    "\n",
    "# elif gran[0] == 'S':\n",
    "# \tfreq = str(dl_interval) + 'S'\n",
    "# \tif len(gran) == 2:\n",
    "# \t\tgranop = 'S0' + dl_interval\n",
    "# \t\tdiff = '0 days, 00:00:0' + dl_interval\n",
    "# \telse:\n",
    "# \t\tgranop = 'S' + str(dl_interval)\n",
    "# \t\tdiff = '0 days, 00:00:' + dl_interval\n",
    "# \toffset = pd.DateOffset(seconds=4800*int(dl_interval))\n",
    "\n",
    "# elif gran[0] == 'D':\n",
    "# \tfreq = 'D'\n",
    "# \tgranop = gran\n",
    "# \tdiff = '1 day, 00:00:00'\n",
    "# \toffset = pd.DateOffset(days=4800*int(dl_interval))\n",
    "\n",
    "\n",
    "# Function to download from oanda\n",
    "def oanda_download(df, x0, xf, gran, instrument):\n",
    "    # Each call of the function downloads data between x0 and xf that hasn't been downloaded previously.\n",
    "    # To make as few requests to oanda as possible, make the interval as large as safely possible.\n",
    "    # Oanda allows 5000 data points at a time; for margin we pull data from up to 4800 time points.\n",
    "    # This is to account for potential duplicate data that'd throw an exception.\n",
    "    if gran[0] == 'S':\n",
    "        offset = pd.DateOffset(seconds=4800*int(gran[1:]))\n",
    "    elif gran[0] == 'M':\n",
    "        offset = pd.DateOffset(minutes=4800*int(gran[1:]))\n",
    "    elif gran[0] == 'H':\n",
    "        offset = pd.DateOffset(hours=4800*int(gran[1:]))\n",
    "    else:\n",
    "        offset = pd.DateOffset(hours=4800*int(gran[1:]))\n",
    "\n",
    "    # If the end point given by user is later than current time, shorten interval.\n",
    "    if dt.datetime.now() < xf:\n",
    "        xf = dt.datetime.now()\n",
    "        \n",
    "    # Download data between x0 and x1, which corresponds to 4800 intervals\n",
    "    x1 = x0 + offset\n",
    "    \n",
    "    # But only download until xf\n",
    "    if x1 > xf:\n",
    "        x1 = xf\n",
    "        \n",
    "    x0_str = x0.strftime('%Y-%m-%dT%H:%M:%S')\n",
    "    x1_str = x1.strftime('%Y-%m-%dT%H:%M:%S')\n",
    "\n",
    "    # Try download. \n",
    "    # If now data available for interval, skip.\n",
    "    try:\n",
    "        tmp = oanda.get_history(instrument=instrument, granularity=gran,\n",
    "                                start=x0_str, end=x1_str).get(\"candles\")\n",
    "\n",
    "        app = pd.DataFrame(tmp, columns=tmp.pop(0)).loc[:, ['time', \n",
    "                                                            'closeBid', 'closeAsk']]\n",
    "        app.columns = ['time',  sym + ' Bid', sym + ' Ask']\n",
    "        app.loc[:, 'time'] = pd.to_datetime(app.loc[:, 'time'])\n",
    "        app = app.set_index('time')\n",
    "        \n",
    "        df = pd.concat([df, app])\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    # Set old x1 as new x1 plus one second for next step and call self again \n",
    "    # as long as xf isn't included in download.\n",
    "    if x1 < xf:\n",
    "        x0 = x1 + pd.DateOffset(seconds=1)\n",
    "        df = oanda_download(df, x0, xf, gran, instrument)\n",
    "        \n",
    "    return df\n",
    "\n",
    "\n",
    "# String names for file naming\n",
    "exportstring = \"data/\" + granop+'_'+y1+'_'+y2\n",
    "importstring = \"data/\" + exportstring\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# List of symbols to download\n",
    "symbols = [\"EUR_AUD\",\"EUR_CAD\",\"EUR_CHF\",\"EUR_GBP\",\"EUR_JPY\", \"USD_MXN\",\n",
    "           \"EUR_NOK\",\"EUR_NZD\",\"EUR_SEK\",\"EUR_SGD\",\"EUR_USD\",\"EUR_ZAR\"]\n",
    "symbolseur = [\"EUR_AUD\",\"EUR_CAD\",\"EUR_CHF\",\"EUR_EUR\",\"EUR_GBP\",\"EUR_JPY\", \"USD_MXN\",\n",
    "              \"EUR_NOK\",\"EUR_NZD\",\"EUR_SEK\",\"EUR_SGD\",\"EUR_USD\",\"EUR_ZAR\"]\n",
    "\n",
    "for sym in symbols:\n",
    "    x0 = dt.datetime(int(y1), 1, 1, 0, 0, 0)\n",
    "    xf = dt.datetime(int(y2),12,31,23,59,59)\n",
    "    # If last date is later than current time, use current time as end point\n",
    "    if dt.datetime.now() < xf:\n",
    "        xf = dt.datetime.now()\n",
    "\n",
    "    # Create data frame \n",
    "    df = pd.DataFrame(data = None, columns = ('time',  sym + ' Bid', sym + ' Ask'))\n",
    "    df = df.set_index('time')\n",
    "    \n",
    "    # See if a file exists with previously downloaded data.\n",
    "    # If it doesn't for y2, loop down to y1; if all fails download from scratch.\n",
    "    yloop = int(y2)\n",
    "    while yloop >= int(y1):\n",
    "        try:\n",
    "            importstring = \"data/\" + granop+'_'+y1+'_'+str(yloop)\n",
    "            df = pd.read_csv(importstring + '_curr_' + sym + '.csv', engine='c',\n",
    "                             index_col=\"time\", parse_dates=True)\n",
    "            last_date = df.index[-1]\n",
    "            print 'Found ' + sym + ' file. xf is ' +  xf.strftime('%Y-%m-%dT%H:%M:%S') +'.'\n",
    "            break\n",
    "        except:\n",
    "            yloop = yloop-1\n",
    "            print yloop\n",
    "    try:\n",
    "        print 'Last date in file is ' +  last_date.strftime('%Y-%m-%dT%H:%M:%S') + '.'\n",
    "    except:\n",
    "        last_date = x0\n",
    "        print 'Could not find or read ' + sym + ' file.'\n",
    "\n",
    "        \n",
    "    df = oanda_download(df, last_date, xf, gran, sym)\n",
    "    df.loc[:, sym] = 0.5*(df.loc[:, sym + ' Bid'] + df.loc[:, sym + ' Ask'])\n",
    "    df.to_csv(exportstring + '_curr_' + sym + '.csv', index=True)\n",
    "    \n",
    "\n",
    "    if sym == symbols[0]:\n",
    "        temp = df.copy()\n",
    "        # 'merged' is the dataframe in which we write all the data, \n",
    "        # so we fill it up with AUD as a starter\n",
    "        merged = temp\n",
    "        # Loop through for all the other currencies\n",
    "    else:\n",
    "        newfile = df.copy()\n",
    "        # Attach a new column to the table for the currency, \n",
    "        # but only take time values which exist for all currencies (inner join).\n",
    "        merged = pd.merge(merged, newfile, how='inner', left_index=True, right_index=True)\n",
    "\n",
    "# Rename dataframe for clarity and select only midpoint columns\n",
    "rates_data = merged.loc[:, symbols]\n",
    "\n",
    "for c in rates_data.columns:\n",
    "    bc = c[:3]\n",
    "    qc = c[4:]\n",
    "    if bc != \"EUR\":\n",
    "        temp_ts = 0.5*(merged.loc[:, c + \" Ask\"]*merged.loc[:, \"EUR_\" + bc + \" Ask\"] +\n",
    "                       merged.loc[:, c + \" Bid\"]*merged.loc[:, \"EUR_\" + bc + \" Ask\"])\n",
    "        temp_ts = np.round(temp_ts, 4)\n",
    "        rates_data.insert(0, \"EUR_\" + qc, temp_ts)\n",
    "\n",
    "# Add a column with the EUR/EUR exchange rate\n",
    "rates_data.insert(0, 'EUR_EUR', 1.)\n",
    "\n",
    "# Sort columns alphabetically by their index\n",
    "rates_data = rates_data.reindex(sorted(rates_data.columns), axis=1).filter(regex=\"EUR_\")\n",
    "\n",
    "# Export dataframe to a csv file. Index false indicates \n",
    "# that we don't want to export the row numbers as well\n",
    "rates_data.to_csv(exportstring+'_rates.csv')\n",
    "\n",
    "\n",
    "# Export all timestamps starting with the second row because that will be the first return we calculate\n",
    "pd.Series(data=rates_data.index.values, name='time').to_csv(exportstring+'_timestamps.csv', \n",
    "                                                            index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Calculate returns, keep only the ones corresponding to the right interval, and rank them\n",
    "return_data = interval_filter(calc_returns(rates_data))\n",
    "ranks_data  = calc_ranks(return_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "return_data.to_csv(exportstring + \"_returns_filtered.csv\", index=True)\n",
    "ranks_data.to_csv(exportstring + \"_ranks_filtered.csv\", index=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
